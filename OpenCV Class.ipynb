{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e6e1bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c8332",
   "metadata": {},
   "source": [
    "# RGB Channel split Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "163d7e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_video_channels(mirror=False):\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cv2.namedWindow('Webcam Life2Coding',cv2.WINDOW_NORMAL)\n",
    "    zeros = None\n",
    "    while True:\n",
    "        ret_val, frame = cap.read()\n",
    "\n",
    "        if ret_val == True:\n",
    "            if mirror:\n",
    "                #flip the image\n",
    "                frame = cv2.flip(frame, 1)\n",
    "\n",
    "            # split the image into its RGB channels\n",
    "            height, width, layers = frame.shape\n",
    "            zeroImgMatrix = np.zeros((height, width), dtype=\"uint8\")\n",
    "\n",
    "            # The OpenCV image sequence is Blue(B),Green(G) and Red(R)\n",
    "            (B, G, R) = cv2.split(frame)\n",
    "\n",
    "            # we would like to construct a 3 channel Image with only 1 channel filled\n",
    "            # and other two channels will be filled with zeros\n",
    "            B = cv2.merge([B, zeroImgMatrix, zeroImgMatrix])\n",
    "            G = cv2.merge([zeroImgMatrix, G, zeroImgMatrix])\n",
    "            R = cv2.merge([zeroImgMatrix, zeroImgMatrix, R])\n",
    "\n",
    "\n",
    "            #we would like to show the 4 images like ( Original | Blue\n",
    "            #                                          Green    | Red  )\n",
    "\n",
    "            # so we need to double the image size as it will be 4 times the original image\n",
    "            final = np.zeros((height * 2, width * 2, 3), dtype=\"uint8\")\n",
    "\n",
    "            final[0:height, 0:width] = frame # 1st Quarter=original\n",
    "            final[0:height, width:width * 2] = B # 2nd Quarter= Blue\n",
    "            final[height:height * 2, 0:width] = G   # 3rd Quarter= Red\n",
    "            final[height:height * 2, width:width * 2] = R  # 4th Quarter= Green\n",
    "\n",
    "            cv2.imshow('Webcam Life2Coding', final)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # if 'q' is pressed then quit\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    split_video_channels(mirror=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f47a50a",
   "metadata": {},
   "source": [
    "# Load and display image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c0ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('panda1.jpg')\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a7600e",
   "metadata": {},
   "source": [
    "# Colour filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "609bf5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('panda1.jpg')\n",
    "#############\n",
    "low_b = np.uint8([200, 200,200])\n",
    "high_b = np.uint8([255, 255, 255])\n",
    "mask = cv2.inRange(img, low_b, high_b)\n",
    "#############\n",
    "cv2.imshow(\"image\",img)\n",
    "cv2.imshow(\"filtered image\", mask)\n",
    "#cv2.resizeWindow(\"image\", 500, 500)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e325d2c",
   "metadata": {},
   "source": [
    "# Display web cam capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9bcf6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "260449d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04bbdd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "#cap.set(3, 160)\n",
    "#cap.set(4, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32919838",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow(\"web cam video\",frame)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0116938",
   "metadata": {},
   "source": [
    "# Changing the colour space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253626a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    ######################\n",
    "    #image = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)  \n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR )\n",
    "    ######################\n",
    "    cv2.imshow(\"web cam video\",image)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f6ece0",
   "metadata": {},
   "source": [
    "# Colour Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54f379ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    ##############\n",
    "    low_b = np.uint8([0, 0,0])\n",
    "    high_b = np.uint8([40,40, 40])\n",
    "    mask = cv2.inRange(frame, low_b, high_b)\n",
    "    ##############\n",
    "    cv2.imshow(\"filtered image\",mask)\n",
    "    cv2.imshow(\"webcam video\",frame)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcfa9a5",
   "metadata": {},
   "source": [
    "# Find the RGB from webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ce88be97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB Format:  [13, 11, 7]\n",
      "Coordinates of pixel: X:  392 Y:  112\n",
      "RGB Format:  [17, 12, 2]\n",
      "Coordinates of pixel: X:  392 Y:  112\n"
     ]
    }
   ],
   "source": [
    "def mouseRGB(event,x,y,flags,param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN: #checks mouse left button down condition\n",
    "        colorsB = frame[y,x,2]\n",
    "        colorsG = frame[y,x,1]\n",
    "        colorsR = frame[y,x,0]\n",
    "        colors = frame[y,x]\n",
    "        #print(\"Red: \",colorsR)\n",
    "        #print(\"Green: \",colorsG)\n",
    "        #print(\"Blue: \",colorsB)\n",
    "        print(\"RGB Format: \",[colorsR,colorsG,colorsB])\n",
    "        print(\"Coordinates of pixel: X: \",x,\"Y: \",y)\n",
    "        \n",
    "\n",
    "cv2.namedWindow('mouseRGB')\n",
    "cv2.setMouseCallback('mouseRGB',mouseRGB)\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    cv2.imshow('mouseRGB', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6272ba1e",
   "metadata": {},
   "source": [
    "# Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5576630",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    ######################\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Find Canny edges\n",
    "    edged = cv2.Canny(gray, 30, 100)\n",
    "    ######################\n",
    "    cv2.imshow(\"Edges\",edged)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce0a2e1",
   "metadata": {},
   "source": [
    "# Drawing contoures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac6aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    low_b = np.uint8([0, 0,0])\n",
    "    high_b = np.uint8([40,40, 40])\n",
    "    mask = cv2.inRange(frame, low_b, high_b)\n",
    "    ##############################\n",
    "    contours, hierarchy = cv2.findContours(mask, 1, cv2.CHAIN_APPROX_NONE)\n",
    "    cv2.drawContours(frame, contours, -1, (0, 255, 0), 3)\n",
    "    ##############################\n",
    "    cv2.imshow(\"filtered video\",mask)\n",
    "    cv2.imshow(\"webcam video\",frame)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde62358",
   "metadata": {},
   "source": [
    "# Edge detection + contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "947ad01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    ##############################\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Find Canny edges\n",
    "    edged = cv2.Canny(gray, 30, 200)\n",
    "    contours, hierarchy = cv2.findContours(edged, 1, cv2.CHAIN_APPROX_NONE)\n",
    "    cv2.drawContours(frame, contours, -1, (0, 255, 0), 3)\n",
    "    ##############################\n",
    "    cv2.imshow(\"With contours\",frame)\n",
    "    cv2.imshow(\"Edged Image\",edged)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a40fb5",
   "metadata": {},
   "source": [
    "# Contour Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3002dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    low_b = np.uint8([0, 0,0])\n",
    "    high_b = np.uint8([40,40, 40])\n",
    "    mask = cv2.inRange(frame, low_b, high_b)\n",
    "    ##############################\n",
    "    contours, hierarchy = cv2.findContours(mask, 1, cv2.CHAIN_APPROX_NONE)\n",
    "    c = max(contours, key=cv2.contourArea)\n",
    "    cv2.drawContours(frame, c, -1, (0, 255, 0), 3)\n",
    "    ##############################\n",
    "    cv2.imshow(\"filtered video\",mask)\n",
    "    cv2.imshow(\"webcam video\",frame)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0040be15",
   "metadata": {},
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Find Canny edges\n",
    "    edged = cv2.Canny(gray, 30, 200)\n",
    "    contours, hierarchy = cv2.findContours(edged, 1, cv2.CHAIN_APPROX_NONE)\n",
    "    ###################################\n",
    "    c = max(contours, key=cv2.contourArea)\n",
    "    cv2.drawContours(frame, c, -1, (0, 255, 0), 3)\n",
    "    ###################################\n",
    "    cv2.imshow(\"With contours\",frame)\n",
    "    cv2.imshow(\"Edged Image\",edged)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c79cc00",
   "metadata": {},
   "source": [
    "# Drawing boxes around contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de26fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    low_b = np.uint8([0, 0,0])\n",
    "    high_b = np.uint8([40,40, 40])\n",
    "    mask = cv2.inRange(frame, low_b, high_b)\n",
    "    contours, hierarchy = cv2.findContours(mask, 1, cv2.CHAIN_APPROX_NONE)\n",
    "    c = max(contours, key=cv2.contourArea)\n",
    "    cv2.drawContours(frame, c, -1, (0, 255, 0), 3)\n",
    "    ############################\n",
    "    color = [255,0,0]\n",
    "    contours_poly = cv2.approxPolyDP(c, 3, True)\n",
    "    boundRect = cv2.boundingRect(contours_poly)\n",
    "    cv2.rectangle(frame, (int(boundRect[0]), int(boundRect[1])),\n",
    "                  (int(boundRect[0]+boundRect[2]), int(boundRect[1]+boundRect[3])), color, 2)\n",
    "    ##############################\n",
    "    cv2.imshow(\"filtered video\",mask)\n",
    "    cv2.imshow(\"webcam video\",frame)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc27087",
   "metadata": {},
   "source": [
    "# K means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27410491",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    ##############\n",
    "    Z = frame.reshape((-1,3))\n",
    "    # convert to np.float32\n",
    "    Z = np.float32(Z)\n",
    "    # define criteria, number of clusters(K) and apply kmeans()\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    K = 2\n",
    "    ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "    # Now convert back into uint8, and make original image\n",
    "    center = np.uint8(center)\n",
    "    res = center[label.flatten()]\n",
    "    res2 = res.reshape((frame.shape))\n",
    "    ##############\n",
    "    cv2.imshow(\"clustured image\",res2)\n",
    "    cv2.imshow(\"webcam video\",frame)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f9e653",
   "metadata": {},
   "source": [
    "### We can count the number of pixels with certain colour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356c9285",
   "metadata": {},
   "source": [
    "# Background Subtraction using Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fe8d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracking\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Object detection from Stable camera\n",
    "motion_detector = cv2.createBackgroundSubtractorMOG2()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    mask = motion_detector.apply(frame)\n",
    "    cv2.imshow(\"motion\",mask)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45c95f24",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:967: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-e0782f383935>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmotion_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"motion\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m0xff\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:967: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "# tracking\n",
    "cap = cv2.VideoCapture('test.mp4')\n",
    "# Object detection from Stable camera\n",
    "motion_detector = cv2.createBackgroundSubtractorMOG2()\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    mask = motion_detector.apply(frame)\n",
    "    \n",
    "    cv2.imshow(\"motion\",mask)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d8404a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
